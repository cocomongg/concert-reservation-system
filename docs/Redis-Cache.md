# Redis를 활용한 성능 개선 보고서

# 캐시 도입
## 1. 캐시 (캐싱) 이란?
- Cache란, 데이터나 값을 미리 복사해 놓는 임시 저장소로서, 자주 사용되는 데이터에 빠르게 접근하기 위해 사용한다.
- Caching이란, Cache에 데이터를 저장하고 관리하는 것을 의미하며, 시스템의 응답 속도 향상과 데이터 베이스의 부하를 줄이기 위해 사용한다.
- 위 설명만 보면 캐시가 무조건적으로 좋아 보이지만, 자주 변경되는 데이터에 대해서는 정합성 문제가 발생할 수 있으며, 자주 사용되는 데이터가 아닌 경우에는 캐시를 사용하지 않는 것이 더 효율적일 수 있다.
- **캐시는 자주 사용(조회)되면서 자주 변경되지 않는 데이터에 대해 사용하는 것이 적합하다.**
<br/>
<br/>

## 2. 로컬 캐시 대신 Redis 캐시를 선택한 이유
- 로컬 캐시란, 애플리케이션 내부 메모리에 데이터를 저장하는 방식으로, 같은 시스템 내에서만 접근이 가능하다. 
속도가 매우 빠르지만, 분산 서버 환경에서는 캐시에 저장된 데이터를 공유할 수 없기 때문에 적절하지 않다.
- Redis는 인메모리 데이터 저장소로 각 서버에서 같은 데이터를 공유할 수 있기 때문에, 분산 서버 환경에서 캐시로 사용하기에 적합하다.
- 현재 시스템은 대규모 트래픽을 처리하기 위해 분산 환경임을 가정했기 때문에 Redis를 캐시로 선택하였다.
<br/>
<br/>

## 3. 채택한 캐싱 전략 패턴
### 채택한 전략
#### 캐시 읽기 전략: Look Aside 패턴
- Read Through 패턴은 단일 장애 지점이 발생할 수 있기 때문에 선택하지 않았다.
- Look Aside 패턴의 데이터 정합성 문제는 수동으로 Cache Warming을 하거나, 적절한 TTL을 설정해서 해결할 수 있다고 판단되어 선택했다.
#### 캐시 쓰기 전략: Write Around 패턴
- 다른 패턴들에 비해 리소스를 효율적으로 사용할 수 있으며, 데이터 손실 문제가 발생하지 않는다고 판단되어 선택했다.

### 캐시 읽기 전략 소개
#### Look Aside 패턴
- 데이터를 찾을 때 캐시에 저장된 데이터가 있는지 먼저 확인하고, 캐시에 데이터가 없으면 DB에서 데이터를 조회하는 패턴
- 장점: 필요한 데이터만 캐시에 로드하여 메모리 사용을 최적화할 수 있고, 반복적으로 동일 쿼리를 수행할 때 좋다. 
- 단점: 캐시에 장애가 발생 시 데이터 정합성 문제가 발생할 수 있다.
<br/>

#### Read Through 패턴
- 캐시에서만 데이터를 읽어오는 전략으로, 애플리케이션이 캐시를 직접 관리하지 않고, 데이터 동기화 라이브러리 등을 사용하는 패턴
- 장점: 캐시와 DB간의 데이터 동기화가 항상 이루어지기 때문에 정합성 문제가 발생하지 않는다.
- 단점: 캐시에서만 데이터를 조회하기 때문에 캐시에 장애가 발생할 경우 서비스 이용에 지장이 생길 수 있다. 
<br/>

### 캐시 쓰기 전략
#### Write Through 패턴
- 데이터를 저장할 때 먼저 캐시에 저장한 다음 바로 DB에 저장하는 패턴
- 장점: 캐시와 DB간의 데이터 동기화가 항상 이루어지기 때문에 정합성 문제가 발생하지 않는다.
- 단점: 데이터 저장 시간이 더 오래 걸리고, 캐싱이 필요하지 않은 데이터도 캐시에 저장되기 때문에 리소스를 낭비할 수 있다.
<br/>

#### Write Behind 패턴
- 데이터를 저장할 때 DB에 바로 저장하지 않고, 캐시에 모아서 배치를 통해 DB에 반영하는 패턴
- 장점: 데이터 저장에 대한 부하를 줄일 수 있다.
- 단점: 캐시에 장애가 발생할 경우 데이터 손실이 발생할 수 있다.
<br/>

#### Write Around 패턴
- 데이터를 저장할 때 바로 DB에 저장하고, 캐시 miss가 발생하는 경우에만 DB와 캐시에 저장하는 패턴
- 장점: 데이터 저장 속도가 빠르다.
- 단점: 캐시와 DB간의 데이터 정합성 문제가 발생할 수 있다.
<br/>
<br/>

## 4. 캐싱을 통해 성능을 개선할 수 있는 로직 분석
### 콘서트 목록 조회
- 대기열 진입 전에 조회되는 데이터이기 때문에 트래픽이 한번에 몰리는 경우가 많다.
- 콘서트 목록은 자주 사용(조회)되면서 자주 변경되지 않는 데이터이기 때문에 캐싱을 하기에 적합하다.

### 예약 가능한 콘서트 스케줄 목록 조회
- 대기열 진입 후에 조회되는 데이터이기 때문에 어느정도 트래픽이 분산되어 발생한다.
- 현재 구현된 로직 상 현재 시간을 기준으로 조회하기 때문에 캐싱을 하더라도 캐시 미스가 발생할 확률이 높기 때문에 캐싱에 적합하지 않다.

### 예약 가능한 좌석 목록 조회
- 좌석 데이터 같은 경우는 변경이 잦기 때문에 캐시 미스가 발생할 확률이 높아 캐싱에 적합하지 않다.

### 대기열 토큰 조회
- 대기열 토큰은 추후 redis에 저장할 예정이기 때문에 고려 대상이 아니다.

### 예약 내역 조회
- 예약 내역 같은 경우는 자주 조회되는 데이터가 아니기 때문에 캐싱에 적합하지 않다.

### 사용자 포인트 잔액 조회
- 사용자 포인트 잔액 같은 경우는 자주 조회되는 데이터가 아니기 때문에 캐싱에 적합하지 않다.

### 정리
- 캐싱은 자주 조회되면서 자주 변경되지 않는 데이터에 대해 사용하는 것이 적합하다.
- **콘서트 목록** 은 자주 조회 되면서 자주 변경되지 않는 데이터이기 때문에 캐시 히트율이 높을 것이라고 예상되며,<br/> 
대기열 진입 전에 조회되는 데이터이기 때문에 DB에 부하를 줄이기 위해 캐싱을 적용하기로 결정했다.
<br/>
<br/>

## 5. 캐싱을 통한 성능 개선 결과
### 테스트 환경
- 테스트 환경: Local
- jmeter를 통해 [콘서트 목록] 조회 시 캐싱을 적용한 전, 후 성능을 측정 및 비교한다.
- 테스트 시나리오는 콘서트 목록 조회(총 1000개의 데이터)를 5초 마다 100명의 사용자가 12번 반복하는 것으로 설정했다.

### 캐시 적용 전 콘서트 목록 조회 성능
![캐시 적용 전](https://github.com/user-attachments/assets/c01447ac-4ab1-49b9-a9d1-7cc92ef95908)
- tps: 197.7/sec
- 평균 응답 시간: 236ms
<br/>
<br/>


### 캐시 적용 후 콘서트 목록 조회 성능
![캐시 적용 후](https://github.com/user-attachments/assets/5d13f0da-be3d-4cf8-ac33-c3b8c9cbf4c2)
- tps: 239.2/sec
- 평균 응답 시간: 12ms

### 성능 개선 결과
- redis 적용 후 tps가 약 1.21배 증가했고, 평균 응답 시간이 224ms 감소한 결과를 확인함으로써 성능이 개선되었다고 할 수 있다.
<br/>
<br/>

## 6. 결론
- 성능을 개선할 수 있는 로직을 분석하고, 캐싱이 적합한 로직에 대해 Redis cache를 적용함으로써 성능이 개선되었다. 분산환경이 아니라면 로컬 캐시를 사용해도 성능이 개선되지만, 현재 가정한 시나리오에서는 <br/>
대규모 트래픽을 처리해야하기에 분산환경임을 가정하고, Redis를 채택하게 되었다. 또한 시나리오에 맞게 효율적으로 캐시를 사용할 수 있도록 Look-Aside + Write-Around 캐시 전략 패턴을 채택했다.<br/>
실제 SpringBoot의 캐싱은 기본적으로 Look-Side 패턴을 사용하기 때문에, 구현을 쉽게 할 수 있었다. 다만 Look-Aside 패턴의 데이터 정합성 문제를 해결하기 위해 TTL을 3분정도로 넉넉히 설정했다.<br/>
추후에는 캐시 히트율을 모니터링 하거나, Cache Warming을 통해 캐시 히트율을 더 높이거나 DB와의 데이터 정합성 문제를 보완할 수 있을 것이다.







